<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AI Voice Companion</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; background-color: #f4f5f7; margin: 0; }
        h1 { color: #172B4D; }
        #recordButton { padding: 15px 30px; font-size: 18px; cursor: pointer; border-radius: 50px; border: none; color: white; transition: background-color 0.3s, transform 0.1s; }
        #recordButton:active { transform: scale(0.95); }
        .recording { background-color: #DE350B; }
        .idle { background-color: #0052CC; }
        .waiting { background-color: #FFAB00; cursor: not-allowed; }
        #status { margin-top: 20px; font-size: 16px; color: #42526E; height: 20px; }
    </style>
</head>
<body>
    <h1>Talk to your AI Companion</h1>
    <button id="recordButton" class="idle">Click to Record</button>
    <p id="status">Status: Idle</p>
    <audio id="audioPlayback" style="display:none;"></audio>

    <script>
        const recordButton = document.getElementById('recordButton');
        const audioPlayback = document.getElementById('audioPlayback');
        const statusElement = document.getElementById('status');
        
        const n8nWebhookUrl = 'https://light47.app.n8n.cloud/webhook/voice-chat';

        let mediaRecorder;
        let audioChunks = [];

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                
                mediaRecorder.addEventListener("dataavailable", event => {
                    audioChunks.push(event.data);
                });

                mediaRecorder.addEventListener("stop", sendAudio);

                mediaRecorder.start();
                
                recordButton.textContent = 'Stop Recording';
                recordButton.className = 'recording';
                statusElement.textContent = "Status: Recording...";
            } catch (err) {
                console.error("Error accessing microphone:", err);
                statusElement.textContent = 'Status: Error - Microphone access denied.';
            }
        }

        function stopRecording() {
            mediaRecorder.stop();
        }

        async function sendAudio() {
            if (audioChunks.length === 0) {
                console.error("Audio chunks are empty. No recording data.");
                statusElement.textContent = "Status: Error - No audio was recorded.";
                recordButton.textContent = 'Click to Record';
                recordButton.className = 'idle';
                return;
            }

            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            console.log(`Created audio blob. Size: ${audioBlob.size} bytes.`);
            
            if (audioBlob.size === 0) {
                console.error("Blob size is 0. Cannot send empty file.");
                statusElement.textContent = "Status: Error - Recorded audio was empty.";
                recordButton.textContent = 'Click to Record';
                recordButton.className = 'idle';
                audioChunks = [];
                return;
            }

            recordButton.textContent = 'Waiting for AI...';
            recordButton.className = 'waiting';
            statusElement.textContent = "Status: Processing...";

            try {
                const response = await fetch(n8nWebhookUrl, {
                    method: 'POST',
                    body: audioBlob,
                    headers: { 'Content-Type': 'audio/webm' }
                });

                if (response.ok) {
                    statusElement.textContent = "Status: Response received!";
                    const audioBlobResponse = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlobResponse);
                    audioPlayback.src = audioUrl;
                    audioPlayback.play();
                    audioPlayback.onended = () => {
                        statusElement.textContent = "Status: Idle";
                        recordButton.textContent = 'Click to Record';
                        recordButton.className = 'idle';
                    };
                } else {
                    const errorText = await response.text();
                    console.error("Error from n8n:", errorText);
                    statusElement.textContent = `Status: Error - ${errorText}`;
                    recordButton.textContent = 'Click to Record';
                    recordButton.className = 'idle';
                }
            } catch (error) {
                console.error("Fetch error:", error);
                statusElement.textContent = `Status: Error - Could not connect to n8n.`;
                recordButton.textContent = 'Click to Record';
                recordButton.className = 'idle';
            }
            audioChunks = [];
        }

        recordButton.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === "recording") {
                stopRecording();
            } else {
                startRecording();
            }
        });
    </script>
</body>
</html>
