<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI Voice Companion</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      background-color: #000;
      color: white;
      font-family: 'Segoe UI', sans-serif;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      overflow: hidden;
    }

    .orb-container {
      position: relative;
    }

    .orb {
      width: 200px;
      height: 200px;
      background: radial-gradient(circle at 30% 30%, #00ffff, #004d4d);
      border-radius: 50%;
      box-shadow: 0 0 40px #00ffff88;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 2; /* Ensures clickability */
      transition: background 0.5s ease, box-shadow 0.5s ease;
    }

    .ring {
      position: absolute;
      top: -20px;
      left: -20px;
      width: 240px;
      height: 240px;
      border-radius: 50%;
      box-shadow: 0 0 30px #00ffff55;
      animation: pulse 2s infinite;
      z-index: 1;
      pointer-events: none; /* Prevents click interference */
    }
    
    .orb.listening {
      background: radial-gradient(circle at 30% 30%, #00ffcc, #005c5c);
      box-shadow: 0 0 50px #00ffff;
    }

    .orb.playing {
      background: radial-gradient(circle at 30% 30%, #ff00ff, #520052);
      box-shadow: 0 0 50px #ff00ff99;
    }

    .ring.listening {
      animation: vibrate 0.4s infinite;
    }

    .ring.playing {
      animation: glow 1s ease-in-out infinite alternate;
    }

    @keyframes pulse {
      0%, 100% { transform: scale(1); opacity: 0.6; }
      50% { transform: scale(1.2); opacity: 1; }
    }

    @keyframes vibrate {
      0% { transform: scale(1.05); }
      50% { transform: scale(1.15); }
      100% { transform: scale(1.05); }
    }

    @keyframes glow {
      0% { box-shadow: 0 0 40px #ff00ff88; }
      100% { box-shadow: 0 0 60px #ff00ffcc; }
    }

    .status-text {
      margin-top: 20px;
      font-size: 18px;
      color: #aaa;
      font-weight: 300;
      font-style: italic;
      min-height: 27px;
    }
  </style>
</head>
<body>
  <div class="orb-container">
    <div id="ring" class="ring"></div>
    <div id="orb" class="orb" title="Click to speak with AI"></div>
  </div>
  <div id="status" class="status-text">Click the orb to speak</div>

  <audio id="beep" src="https://www.soundjay.com/button/sounds/button-3.mp3" preload="auto"></audio>

  <script>
    const orb = document.getElementById('orb');
    const ring = document.getElementById('ring');
    const statusText = document.getElementById('status');
    const beep = document.getElementById('beep');

    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;

    // Function to send audio data to n8n and handle the audio response
    function sendToN8n(base64Audio) {
        statusText.textContent = "Processing...";

        // This is your working n8n production webhook URL
        const n8nWebhookUrl = 'https://light47.app.n8n.cloud/webhook/ai-voice-input';

        fetch(n8nWebhookUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                audioData: base64Audio,
                fileName: `recording-${new Date().toISOString()}.webm`
            }),
        })
        .then(response => {
            if (!response.ok) throw new Error(`Server response was not ok: ${response.status}`);
            return response.blob();
        })
        .then(audioBlob => {
            const audioURL = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioURL);

            audio.onplay = () => {
              orb.classList.add('playing');
              ring.classList.add('playing');
              statusText.textContent = "Responding...";
            };

            audio.onended = () => {
              orb.classList.remove('playing');
              ring.classList.remove('playing');
              statusText.textContent = "Click the orb to speak";
            };

            audio.play();
        })
        .catch(err => {
            console.error("Error communicating with n8n:", err);
            statusText.textContent = "Error communicating with AI.";
            orb.classList.remove('listening', 'playing');
            ring.classList.remove('listening', 'playing');
        });
    }

    // Function to start recording audio
    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        isRecording = true;
        audioChunks = [];
        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.addEventListener("dataavailable", event => {
          audioChunks.push(event.data);
        });

        mediaRecorder.addEventListener("stop", () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const reader = new FileReader();
          reader.readAsDataURL(audioBlob);
          reader.onloadend = () => {
            const base64String = reader.result;
            sendToN8n(base64String);
          };
        });

        beep.play();
        mediaRecorder.start();
        orb.classList.add('listening');
        ring.classList.add('listening');
        statusText.textContent = "Listening...";
      } catch (error) {
        console.error("Error accessing microphone:", error);
        statusText.textContent = "Error: Microphone permission denied.";
        isRecording = false;
      }
    }

    // Function to stop recording
    function stopRecording() {
      if (mediaRecorder) {
        mediaRecorder.stop();
        isRecording = false;
        orb.classList.remove('listening');
        ring.classList.remove('listening');
      }
    }

    // Main click handler for the orb
    orb.addEventListener('click', () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    });

  </script>
</body>
</html>
